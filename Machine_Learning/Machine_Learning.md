+++
date = '2025-05-22T16:36:28+08:00'
draft = true
title = 'Machine-Learning'
math = true
license = ""
description = ""
categories = [
    "学习笔记"
]
tags = [
    "Machine Learning"
]
image = ""

+++



## 引言
### 什么是机器学习
定义如下，一个程序被认为能从 **经验 E** 中学习，解决 **任务 T**，达到 **性能度量值 P**，当且仅当，有了经验 E 后，经过 P 评判，程序在处理 T 时的性能有所提升。

例如下棋游戏:  
E 就是程序上万次的自我练习的经验。  
T 就是下棋。  
P 就是它在与一些新的对手比赛时，赢得比赛的概率。  

### 监督学习
**监督学习** 指的就是我们给学习算法一个 **数据集**。这个数据集由“正确答案”组成。学习算法再根据这个数据集作出预测，算出更多的正确答案。  
监督学习的两个例子, **回归问题 与 分类问题**。

回归问题 : 推测出一个 **连续** 值的输出结果。  
例如 : 卖水果，数据集 3 斤卖 10 元左右，预测 4 斤能卖多少。

分类问题 : 推测出一组 **离散** 的结果。  
例如 : 识别红绿灯。  

### 无监督学习
**无监督学习** 指的是一种学习策略，它交给算法大量的数据，并让算法为我们从数据中找出某种结构。  
无监督学习中 **已知数据没有任何的标签** 是指数据 **有相同的标签或者就是没标签**。  
无监督学习的例子，**聚类算法、鸡尾酒算法**

聚类算法 : 将数据分为几类不同的 **簇**。  
例子 : 谷歌新闻，同一主题新闻归为一类; 市场分割。

鸡尾酒算法 : 分离麦克风接收到的不同的人的声音与环境声音。

## 单变量线性回归(Linear Regression with One Variable)
### 模型表示
样本数目 : 小写 **m**  
训练集 : **Training Set**  
特征/输入变量 : **$x$**  
目标/输出变量 : **$y$**  
训练集中的实例 : **($x$, $y$)**  
第 $i$ 个观察实例 : **($x^{(i)}$, $y^{(i)}$)**  
**学习算法的解决方案或函数也称为假设(hypothesis) : h**

模型表示就是找到将训练集给学习算法找到一个合适的函数 $h$ , $y = h(x)$

函数 $h_\theta(x) = \theta_0 + \theta_1x$  
由于只含有一个特征/输入变量，因此这样的问题叫做单变量线性回归问题。

### 代价函数
建模误差: 模型所预测的值与训练集中实际值之间的差距 $h_\theta(x^{(i)}) - y^{(i)}$

平方误差函数 $J(\theta_0,\theta_1) = \frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2$  
平方误差函数是代价函数之一，对于大多数问题，特别是回归问题，其都是个合理的选择。  
为什么是 $\frac{1}{2m}$:  
除以 m 是为了消除样本数量 m 对 J 的影响  
除以 2 是为了抵消对 J 关于 θ 求偏导数时式子多出的一个 2，使计算更方便  


我们的目标就是找到一个合适的参数 $\theta_0,\theta_1$ 使得代价函数最小。 即 Goal: $\underset{\theta_0,\theta_1}{minimize}J(\theta_0,\theta_1)$


### 梯度下降
梯度下降是一个用来 **求函数最小值** 的算法，可以用其来求出使代价函数 $J$ 最小的参数 $\theta_0$ 和 $\theta_1$ 的值。  

**梯度下降的思想** : 开始时，随机选择一组参数 $(\theta_0,\theta_1)$, 计算代价函数, 然后寻找下一个能让代价函数下降最多的参数组合。持续这种操作，直至找到一个局部最小值。  
局部最小值不等同于全局最小值。不同的初始参数会可能会得到完全不同的局部最小值。  

#### 批量梯度下降算法(batch gradient descent)
批量 batch 指的是，在梯度下降的每一步中，都用到来所有的训练样本。  

公式为: 
$$
\begin{aligned}
&\text{repeat until convergence（重复直至收敛）} \{ \\
&\quad \theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta_0, \theta_1) \quad (\text{for } j = 0 \text{ and } j = 1) \\
&\}
\end{aligned}
$$

其中 $\alpha$ 是学习率，其决定了我们沿代价函数梯度方向向下迈出的幅度有多大。  
$\alpha$ 太小，需要很多步才能够达到局部最低点。  
$\alpha$ 太大，梯度下降法可能会越过最低点，甚至可能无法收敛，导致发散。  

在梯度下降法中，当参数取值接近局部最低点时，梯度下降法会自动采取更小的幅度，因为代价函数导数会趋向于 0。  



## 多变量线性回归

### 多维特征

新的注释：  

$n$ 代表特征的数量  

$x^{(i)}$ 代表第 $i$ 个训练实例，是特征数据的第 $i$ 行，是一个 **向量 ** 

$x_j^{(i)}$ 代表特征矩阵中第 $i$ 行第 $j$ 个特征  

多变量的假设 $h$ 表示为：  
$$
h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+...+\theta_nx_n
$$
此时模型中参数为一个 $n+1$ 维向量  

任何一个训练实例也都是一个 $n+1$ 维向量  

特征矩阵 X 的维度是 $m*(n+1)$  

因此公式可以简化为  

$$
h_\theta(x)=\theta^TX
$$


### 多变量梯度下降

代价函数为所有建模误差的平方和，即:  
$$
J(\theta_0,\theta_1,...,\theta_n)=\frac{1}{2m}\sum^m_{i = 1}(h_\theta(x^{(i)})-y^{(i)})^2
$$

多变量线性回归的批量梯度下降算法为：
$$
\begin{aligned}
&\text{repeat} \{ \\
&\quad \theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta_0, \theta_1,...\theta_n) \\ 
&\}
\end{aligned}
$$


即:

$$
\begin{aligned}
&\text{repeat} \{ \\
&\quad \theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} \frac{1}{2m} \sum^m_{i = 1}(h_\theta(x^{(i)})-y^{(i)})^2 \\
&\}
\end{aligned}
$$
求导后得到：
$$
\begin{aligned}
&\text{repeat} \{ \\
&\quad \theta_j := \theta_j - \alpha  \frac{1}{m} \sum^m_{i = 1}(h_\theta(x^{(i)})-y^{(i)}) \cdot x_j^{(i)} \\
&\}
\end{aligned}
$$

### 梯度下降法 

#### 特征缩放

使特征具有相近的尺度有助于梯度下降宣发更快的收敛。  

方法：将所有特征的尺度都尽量缩放到-1 到 1 **这种小范围** 内，也不能太小。  

最简单的，令 $x_n=\frac{x_n-\mu_n}{s_n}$, 其中 $\mu_n$ 是平均值，$s_n$ 是标准差。  

#### 学习率

梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，可以绘制 **迭代次数-代价函数** 的图表来观测算法在何时收敛。 



梯度下降算法的每次迭代受学习率 $\alpha $ 影响：  

1. $\alpha$ 太小，则到达收敛所需的迭代次数很大，但理论上终会收敛。  
2. $\alpha $ 太大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。  



调整学习率时可以采用以下 **策略**：从 0.001 开始每次上在原基础上乘 3 倍，**最终选择一个较大的可以使得代价函数收敛的 $\alpha $**。  

如：0.001，0.003，0.01，0.03，0.1

### 特征选择与多项式回归

#### 特征选择

建立模型时，可以 **根据需要选择适合模型的特征** 而不局限于数据集中的特征。比如：数据集给出房子的长和宽，预测房价时，可以创造一个特征为 **面积 = 长 *宽** 作为模型的新特征。  

#### 多项式回归

**线性回归并不适合所有数据**，有时需要曲线来适应数据，比如：

三次方模型 $h_\theta(x)=\theta_0 + \theta_1 x + \theta_2 x^2 + \theta_3 x^3$  

使用多项式回归模型，特征缩放很有必要。   



### 正规方程

当特征数量小于 10000 时（对于目前的计算机），通常采用正规方程的方法找到一组最优参数 $\theta$。  

正规方程是通过求解下面的方程来找出使得代价函数最小的参数的：$\frac{\partial}{\partial \theta_j} J(\theta_j)=0$，

其 **解** 为 $\theta=(X^TX)^{-1}X^Ty$。$X$ 为训练集特征矩阵，$y$ 为训练集结果。  

#### 梯度下降于正规方程的比较

|        梯度下降         |                           正规方程                           |
| :---------------------: | :----------------------------------------------------------: |
| 需要选择学习率 $\alpha $ |                            不需要                            |
|      需要多次迭代       |                         一次运算得出                         |
|   特征数量 n 大时也可用   | 矩阵逆的计算时间复杂度为 $O(n^3)$。因此 n 小于 10000 时，可以接受 |
|     使用于各种类型      |         只适用于线性模型。不适合逻辑回归等其它模型。         |



以下情况时，正规方程不能用：  

1. 有两个特征线性相关。  解决：使用正规方程前，剔除相关特征。  
2. 含有大量特征，进而出现 $m \leqslant n$ 时。  解决：剔除特征，用较少特征反应尽可能多的内容。  

## 逻辑回归

逻辑回归算法是一种分类算法。  

分类问题预测的变量 $y$ 为 **离散值**。

### 假说表示

引入一个 **逻辑函数 Sigmoid function**，S 形函数，公式为 $g(z)=\frac{1}{1+e^{-z}}$。其图像如下所示：

<center>
    < img src = "https://raw.githubusercontent.com/heimi2022/img-repo0/main/Machine_Learning_sigmoid_function.png"
         width = "40%" >
    <br>
    sigmoid function
</center>

令逻辑回归模型的假设是：$h_\theta(x)=g(\theta^T X)$, $X$ 代表特征向量，$g$ 代表逻辑函数。  

此时模型的输出变量范围始终在 0 和 1 之间。   

$h_\theta(x)$ 表示，对于给定的输入变量，根据选择的参数，计算输出变量为 1 的可能性，即：
$$
h_\theta(x)= P(y = 1|x;\theta)
$$

### 决策边界

在逻辑回归中，假设：  
$$
y = \begin{cases}
1, & \text{if } h_\theta(x) \geq 0.5 \\
0, & \text{if } h_\theta(x) < 0.5
\end{cases}
$$

因此当 $\theta^T x \geqslant 0$ 时，预测 $y=1$，当 $\theta^T x < 0$ 时，预测 $y=0$。  

因此对于一组参数 $\theta$，有 $\theta^T x=0$，这条 **曲线** 即为模型的决策边界。  

### 代价函数

为什么逻辑回归的代价函数和线性回归的不同？由于 sigmoid 函数的非线性，导致逻辑回归的假设函数带入代价函数时，会导致代价函数有很多局部最小值，其是一个非凸函数。因此需对代价函数进行修正。

定义逻辑回归的代价函数 $J(\theta)=\frac{1}{m} \sum^m_{i=1} Cost(h_\theta(x^{(i)}),y^{(i)})$，其中
$$
Cost(h_\theta(x^{(i)}), y^{(i)}) = \begin{cases}
   -log( h_\theta(x)) \quad &  if\quad y = 1, &  \\
   -log( 1- h_\theta(x)) &  if\quad y = 0, &  \\
\end{cases}
\overset{简化}{=} -ylog( h_\theta(x))-(1-y)log( 1- h_\theta(x))
$$

#### 逻辑回归中 Cost 函数特点

当实际的 $y=1$ 且 $h_\theta(x)=1$ 时，误差为 0，当 $y=1$ 但 $h_\theta(x)$ 不为 1 时，误差随着 $h_\theta(x)$ 的变小而变大。当 $h_\theta(x)$ 减小为 0，表示预测与实际完全相反，其误差为无穷大，这时代价函数将会受到很大的惩罚；当实际的 $y=0$ 且 $h_\theta(x)=0$ 时，误差为 0，当 $y=0$ 但 $h_\theta(x)$ 不为 0 时，误差随着 $h_\theta(x)$ 的变大而变大。

#### 简化后的代价函数

$$
\begin{aligned}
J(\theta)& = \frac{1}{m} \sum^m_{i = 1} Cost(h_\theta(x^{(i)}), y^{(i)}) & \\
& = -\frac{1}{m} [\sum^m_{i = 1}-ylog( h_\theta(x))-(1-y)log( 1- h_\theta(x))] &\\
\end{aligned}
$$

最小化代价函数的方法 **是梯度下降法**：
$$
\begin{aligned}
&\text{Repeat} \{ \\
& \theta_j := \theta_j - \alpha \frac{1}{m} \sum^m_{i = 1}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)} \\
&\}
\end{aligned}
$$

虽然其形式上与线性回归的梯度下降法相同，但由于回归的模型假设发生了变化，两者是完全不同的函数。  



### 高级优化

优化算法：共轭梯度法 BFGS（变尺度法）和 L-BFGS（限制遍尺度法）。  

优点：不需要手动选择学习率。  

### 多类别分类

假设有 n 个类别，则将其分为 **n 个** 1 对（n-1）的 **二元分类问题**。  

记每一个分类问题的模型为：$h_\theta ^{(i)} (x)= p(y=i|x;\theta)$，其中 $i=(1,2,3,...,k)$。   

最终输出结果为让 $h_\theta ^{(i)} (x)$ 最大的 i，即 $\mathop{max}\limits_{i} \; h_\theta ^{(i)} (x)$。  

## 正则化

### 过拟合

**过拟合** 指通过学习得到的假设可能能够非常好的适应训练集（代价函数可能几乎为 0），但是可能 **不会** 推广到预测新的数据。    

当有 **过多的变量但只有很少的训练数据** 时很容易出现过拟合问题。  

**欠拟合** 指模型不能适应训练集。

#### 解决过拟合

1. 减少特征变量的数目 -- 人工选择去除一些变量；模型算法选择（如 PCA）。
2. **正则化** -- 保留所有的特征变量，但减小参数 $\theta$ 的大小。 其适用于有很多特征变量，且每一个特征变量看起来对预测结果都有一点用的情况。  

### 代价函数

#### 正则化的直观理解

假设模型为 $h_\theta(x)=\theta_0 + \theta_1 x + \theta_2 x^2 + \theta_3 x^3 + \theta_4 x^4$，且高次项导致了过拟合的产生，则 **假如能让高次项的系数趋向于 0，就能够缓解过拟合的问题** 了。 因此修改代价函数 ，对 $\theta_3 \text{和}\theta_4$ 设置一些惩罚，如下所示：
$$
J(\theta)=\frac{1}{2m}[\sum^m_{i = 1}(h_\theta(x^{(i)})-y^{(i)})^2+1000 \theta_3^2 + 1000 \theta_4^2]
$$
则通过这样的代价函数选择出来的 $\theta_3 \text{和}\theta_4$ 对预测结果的影响就很小了。

#### 带正则化参数的代价函数

修改后的代价函数如下：
$$
J(\theta)=\frac{1}{2m}[\sum^m_{i = 1}(h_\theta(x^{(i)})-y^{(i)})^2+\lambda \sum^n_{j = 1}\theta_j^2]
$$
其中，$\lambda$ 成为正则化参数。  

假如 $\lambda$ 太大，则所有 $\theta$ 都会趋于 0，除了 $\theta_0$，这样最终模型为一条平行于 x 轴的直线，导致欠拟合。

### 正则化线性回归

#### 梯度下降

$$
\begin{aligned}
& \text{Repeat until convergence} \{ \\
& \theta_0 := \theta_0 - \alpha \frac{1}{m} \sum^m_{i = 1} (h_\theta(x^{(i)})-y^{(i)})x_0^{(i)} \\
& \theta_j := \theta_j(1-\alpha \frac{\lambda}{m}) - \alpha \frac{1}{m} \sum^m_{i = 1} (h_\theta(x^{(i)})-y^{(i)})x_j^{(i)} \\
& \}
\end{aligned}
$$

正则化线性回归的梯度下降算法的变化在于，每次都在原有算法更新柜子的基础上令 $\theta$ 值减少了一个额外的值。  



#### 正规化

$$
\theta = (X^T X + \lambda \begin{bmatrix}
0 & & & & & \\
& 1 & & & & \\
& & 1 & & & \\
& & & \cdot & & \\
& & & & \cdot & \\
& & & & & 1 \\
\end{bmatrix}^{-1})^{-1} X^Ty
$$

图中矩阵尺寸为 $(n+1)*(n+1)$

### 正则化逻辑回归

正则化逻辑回归的代价函数：
$$
J(\theta) = \frac{1}{m} [\sum^m_{i = 1}-ylog( h_\theta(x))-(1-y)log( 1- h_\theta(x))] + \frac{\lambda}{2m} \sum^n_{j = 1}\theta^2_j 
$$
则梯度下降算法为：
$$
\begin{aligned}
& \text{Repeat until convergence} \{ \\
& \theta_0 := \theta_0 - \alpha \frac{1}{m} \sum^m_{i = 1} (h_\theta(x^{(i)})-y^{(i)})x_0^{(i)} \\
& \theta_j := \theta_j(1-\alpha \frac{\lambda}{m}) - \alpha \frac{1}{m} \sum^m_{i = 1} (h_\theta(x^{(i)})-y^{(i)})x_j^{(i)} \\
& \}
\end{aligned}
$$

## 神经网络

### 模型表示

神经网络模型建立在很多神经元之上，每一个神经元又是一个学习模型。这些神经元也叫激活单元（activation unit）。

神经网络模型是许多逻辑单元按照不同的层级组织起来的网络，每一层的输出变量都是下一层的输入变量。  

引入以下标记法来描述模型：

1. $\alpha _i ^{(j)}$ 代表第 $j$ 层的第 $i$ 个激活单元。
2. $\theta^{(j)}$ 代表从第 $j$ 层映射到第 $j+1$ 层时的权重矩阵。其 **尺寸** 为以第 $j+1$ 层的激活单元数量作为行数，以第 $j$ 层的激活单元数量 **加一** 作为列数。

#### 举例

<center>
    < img src = "https://raw.githubusercontent.com/heimi2022/img-repo0/main/Machine_Learning_Neural_Network_layer3_example"
         width = "40%" >
    <br>
    3-Layer Neural model
</center>


对于上图所示模型，激活单元和输出分别表达为：
$$
\begin{aligned}
& \alpha_1^{(2)}= g(\Theta_{10}^{(1)}x_0 + \Theta_{11}^{(1)}x_1  + \Theta_{12}^{(1)}x_2  + \Theta_{13}^{(1)}x_3 ) \\
& \alpha_2^{(2)}= g(\Theta_{20}^{(1)}x_0 + \Theta_{21}^{(1)}x_1  + \Theta_{22}^{(1)}x_2  + \Theta_{23}^{(1)}x_3 ) \\
& \alpha_3^{(2)}= g(\Theta_{30}^{(1)}x_0 + \Theta_{31}^{(1)}x_1  + \Theta_{32}^{(1)}x_2  + \Theta_{33}^{(1)}x_3 ) \\
& h_\theta(x)= g(\Theta_{10}^{(2)}\alpha_0^{(2)} + \Theta_{11}^{(2)}\alpha_1^{(2)}  + \Theta_{12}^{(2)}\alpha_2^{(2)}  + \Theta_{13}^{(2)}\alpha_3^{(2)} ) \\
\end{aligned}
$$
将例中这种从左往右的算法称为 **向前传播算法**。

若只看输出部分，其输出方式类似逻辑回归模型，可以将 $\alpha $ 看成是更高级的特征值。

**多类分类** 问题：输出层用 n 个神经元，表示 n 类。

## 神经网络的学习

### 代价函数

新的标记方法：

假设神经网络的训练样本由 $m$ 个，每个包含一组输入 $x$ 和一组输出信号 $y$  

$L$ 表示神经网络的层数  

$S_l$ 表示 $l$ 层中神经元的个数，$S_L$ 表示最后一层中神经元的个数  

神经网络的分类定义为两种情况：二类分类和多类分类，

1. 二类分类：$S_L=1$, $y=0 \text{ or } 1$
2. $K$ 类分类：$S_L=k$, $y_i=1$ 表示分到第 $i$ 类；$(K>2)$

在神经网络中，$h_\theta(x)$ 是一个维度为 $K$ 的向量，则：$h_\theta(x) \in R^K,(h_\theta(x))_i=i^{th} output$

代价函数如下：
$$
J(\Theta)=-\frac{1}{m}[\sum_{i = 1}^m \sum_{k = 1}^k y_k^{(i)}log(h_\Theta(x^{(i)}))_k + (1 - y_k^{(i)})log(1 - (h_\Theta(x^{(i)}))_k) ] + \frac{\lambda}{2m}\sum_{l = 1}^{L-1}\sum_{i = 1}^{s_l}\sum_{j = 1}^{s_l+1}(\Theta_{ji}^{(l)})^2
$$

1. 对于每一行特征：由于有 $K$ 个特征，可以利用循环，对每一行特征都预测 $K$ 个不同结果，然后利用循环将 $K$ 个预测偏差累加。
2. 对于正则化这一项，遍历所有层的所有参数。

### 反向传播算法

为了 **计算代价函数的偏导数** $\frac{\partial}{\partial\theta_{ij}^{(l)}}J(\Theta)$，需要采用一种反向传播算法。  

反向传播算法：首先计算最后一层的误差，然后再一层一层反向求出各层的误差，直到倒数第二层。  

#### 反向传播算法中误差的计算

用 $\delta$ 来表示误差。对于一个 4 层的网络，反向传播误差分 3 步计算：

1. $\delta^{(4)}=a^{(4)}-y$
2. $\delta^{(3)}=(\Theta^{(3)})^T \delta^{(4)}*g'(z^{(3)})$，$g'(z^{(3)})$ 是 sigmoid 函数的导数，且 $g'(z^{(3)})= a^{(3)} * (1 - a^{(3)})$，$(\Theta^{(3)})^T \delta^{(4)}$ 是权重导致的误差的和。
3. $\delta^{(2)}=(\Theta^{(2)})^T \delta^{(4)}*g'(z^{(2)})$

对于 4 层的网络，设隐藏层都只有两个神经元，则 $\delta_2^{(2)}=\Theta_{12}^{(2)} \delta_1^{(3)}+\Theta_{22}^{(2)} \delta_2^{(3)}$。

#### 忽略代价函数中的正则化项

**忽略代价函数中正则化项，则 $\frac{\partial}{\partial\theta_{ij}^{(l)}}J(\Theta)=a_j^{(l)} \delta_i^{l+1}$。其中上下标的含义：**

$l$ 代表目前所计算的是第几层

$j$ 代表目前计算层中的激活单元的下标，也就是下一层第 $j$ 个输入变量的下标  

$i$ 代表下一层中误差单元的下标

#### 考虑正则化处理

则用 $\Delta_{ij}^{(l)}$ 来表示误差矩阵，则算法表示为：
$$
\begin{aligned}
\text{for } i = 1 : m \quad \{ \\
\quad & a^{(1)} := x^{(i)} \\
\quad & \text{向前传播计算 } a^{(l)} \text{ for } l = 1, 2, 3, \dots, L \\
\quad & \text{using } \delta^{(L)} := a^{(L)} - y^{(i)} \\
\quad & \text{执行向后传播算法计算直至第二层的所有误差} \\
\quad & \Delta^{(l)}_{ij} := \Delta^{(l)}_{ij} + a^{(l)}_j \delta^{(l+1)}_i \\
\}
\end{aligned}
$$
在求出了 $\Delta_{ij}^{(l)}$ 之后，则可求出代价函数的偏导数：
$$
\frac{\partial}{\partial\theta_{ij}^{(l)}}J(\Theta)= D_{ij}^{(l)}:= \begin{cases}
\frac{1}{m}\Delta_{ij}^{(l)}+\lambda \Theta_{ij}^{(l)}& ,\quad if \quad j \ne 0 \\
\frac{1}{m}\Delta_{ij}^{(l)}&, \quad if \quad j = 0
\end{cases}
$$

### 梯度检验

对一个复杂模型使用梯度下降算法时，可能会存在一些不易察觉的错误，意味着虽然代价看上去不断减小，但是最终的结果可能并不是最优解。 

**解决方法：梯度检验**。

**思想**：通过估计梯度值来检验我门计算的导数值是否真的是预期的。

**方法**：在代价函数上，对于某个特定的 $\theta$，我们计算出在 $\theta - \epsilon $ 处和 $\theta + \epsilon $ 的代价值，然后求两个代价的平均，即为估计值。

针对 $\theta_1$ 进行检验的示例：
$$
\frac{\partial}{\partial_{\theta_1}}=\frac{J(\theta_1 + \epsilon,\theta_2,\cdots,\theta_n)-J(\theta_1 - \epsilon,\theta_2,\cdots,\theta_n)}{2 \epsilon}
$$
对于反向传播算法，计算出的偏导数存储在矩阵 $D_{ij}^{(l)}$ 中，检验时，将该矩阵展开成为向量；与此同时，将 $\theta$ 矩阵也展开为向量，针对每一个 $\theta$ 都计算一个近似的梯度值，将这些值存储于一个近似梯度矩阵中，同 $D_{ij}^{(l)}$ 比较。



### 随机初始化

任何优化算法都需要一些初始的参数。

对于神经网络，**令所有的初试参数都为一个相同的值是不可行的**，这意味着对于一个层的所有激活单元都为相同的值。进而在梯度下降时，对于每一个激活单元的误差都是相同的，这意味着高度的冗余。因此需要对参数进行随机初始化。



### 神经网络的训练

#### 网络结构

第一层的单元数：训练集的特征数量

最后一层的单元数：训练集的结果的类的数量

隐藏层：该层大小最好为 1。如果层数大于 1，应确保每个隐藏层的单元个数相同，通常情况下隐藏层单元个数越多越好。



#### 训练神经网络

1. 参数随机初始化
2. 正向传播算法，计算所有的 $h_\theta(x)$
3. 选择代价函数
4. 反向传播算法，计算所有偏导数
5. 梯度检验
6. 使用优化算法来最小化代价函数

## 机器学习诊断法

### 评估一个假设

如何 **评估一个假设是否过拟合** 呢？ 将训练数据分为训练集和测试集。 一般训练集：测试集 = 7：3。

#### 用测试集计算误差

对于线性回归模型，可以利用测试集数据计算代价函数 $J$。

对于逻辑回归模型，除了可以用测试集数据计算代价函数外，还可利用误分类的比率对每一个测试集实例计算：
$$
err(h_\theta(x), y)= \begin{cases}
1,&if \quad h_\theta(x) \ge 0.5 \quad and \quad y = 0, or \quad if \quad h_\theta(x) < 0.5 \quad and \quad y = 1  \\
0，&其它
\end{cases}
$$
然后对计算结果求平均。

### 模型选择和交叉验证集

越高次数的多项式模型越能够适应训练数据集，但适应训练数据集的模型不一定能够推广到一般状况。**可以使用交叉验证集，简称验证集，来帮助选择模型**。

典型的数据集的 **比例**，训练集：验证集：测试集 = 6：2：2。

#### 模型选择方法

1. 使用训练集训练出几个模型
2. 用几个模型分别对验证集计算得出交叉验证误差（代价函数的值）
3. 选取代价函数值最小的模型
4. 用步骤 3 中选出的模型对测试集计算得出推广误差。

### 模型阶数和偏差/方差

对于训练集，当模型阶数 $d$ 较小时，模型的拟合程度低，误差较大。随着 $d$ 的增长。拟合程度提高，误差减小。

对于验证集，误差随着 $d$ 先减小后增大，转折点为模型开始过拟合的时候。

训练集误差和验证集误差都比较大，且接近时： 偏差/欠拟合。

验证集误差远大于训练集误差时：方差/过拟合。

<center>
    < img src = "https://raw.githubusercontent.com/heimi2022/img-repo0/main/Machine_Learning_bias_var_polynomial_d_curve"
         width = "40%" >
    <br>
    polynomial_d
</center>

### 正则化和偏差/方差

#### 选择正则化参数

1. 使用训练集训练几个不同程度正则化的模型。正则化参数一般从小到达，按 2 的倍数增加。
2. 用这几个模型分别对验证集计算交叉验证误差
3. 选择得出交叉验证误差最小的模型
4. 用步骤 3 中选出的模型对测试集计算得出推广误差

#### 偏差和方差

当 $\lambda$ 较小时。表现为方差，训练集误差较小（过拟合），交叉验证集误差较大。

随着 $\lambda$ 的增加，训练集误差不断增加（欠拟合），交叉验证集误差先减小后增大。

<center>
    < img src = "https://raw.githubusercontent.com/heimi2022/img-repo0/main/Machine_Learning_bias_var_regularization_curve"
         width = "40%" >
    <br>
    Bias/variance as function of the regularzation 
</center>

### 学习曲线

#### 高偏差，欠拟合

对于高偏差，欠拟合的情况，曲线如下图所示：

<center>
    < img src = "https://raw.githubusercontent.com/heimi2022/img-repo0/main/Machine_Learning_High_bias_learning_curve"
         width = "40%" >
    <br>
    High bias
</center>



曲线有如下特点：对于验证集和训练集，误差都很大，且二者很接近。无论训练集多大，其误差不会有太大改变

#### 高方差，过拟合

对于高偏差，欠拟合的情况，曲线如下图所示：

<center>
    < img src =" https://raw.githubusercontent.com/heimi2022/img-repo0/main/Machine_Learning_High__variance_learning_curve "
         width = "40%" >
    <br>
    High variance
</center>

曲线有以下特点，训练集误差很小，验证集误差很大。但是增加训练集数据可以提高模型效果。

### 总结

解决高方差：获取更多的训练数据，尝试减少特征的数量，增加正则化程度

解决高偏差：增加特征的数量，增加多项式特征，减小正则化程度

较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合。
较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合，但可以通过正则化手段来调整而更加适应数据。  

通常选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。

对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数。

## 误差分析

### 构建一个学习算法的方法：

1. 从一个简单且能快速实现的算法开始，实现并用验证集测试这个算法
2. 绘制学习曲线，决定增加更多数据 or 添加更多特征.....
3. 进行误差分析

### 类偏斜的误差度量

类偏斜情况表现为我们的训练集中有非常多的同一种类的实例，只有很少或没有其他类的实例。  

|                      | **Positive（预测）** | **Negtive（预测）** |
| -------------------- | -------------------- | ------------------- |
| **Positive（实际）** | TP                   | FN                  |
| **Negtive（实际）**  | FP                   | TN                  |

**TP**：正确肯定，预测为真，实际为真

**FP**：错误肯定，预测为真，实际为假

**TN**：正确否定，预测为假，实际为假

**FN**：错误否定，预测为假，实际为真

**查准率（Precision）：** $P=\frac{TP}{TP+FP}$。在预测的所有真的里面，实际上为真的比例。

**查全率(Recall)：** $R=\frac{TP}{TP+FN}$。在所有实际上为真的里面，预测为真的比例。

### 查准率和查全率之间的平衡

假如 $h_\theta(x)\ge p$ 预测为真，那么将 p 调大，查准率上升，查全率下降；将 p 调小，查准率下降，查全率上升。
又因为我们希望两者都比较大，则我们需要做一个权衡。

选择阈值的方法，一种是 **计算 F1 值(F1 Score)**。其计算公式为：
$$
F1 \, Score = 2\frac{PR}{P+R}
$$
应选择使得 F1 值最高的阈值。

## 支持向量机（SVM）

### SVM 定义

SVM：
$$
\underset{\theta}{min}C\sum^m_{i = 1}[y^{(i)}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})]+\frac12\sum^n_{i = 1}\theta^2_j, C =\frac1\lambda
$$
这里将正则化常数移到了第一项。在逻辑回归中，若 $\lambda$ 很大，则意味着给正则化项一个很大的权重。在这里若 $C$ 很小, 则也等同于给正则化项一个很大的权重。

$C$ 较大时，相当于 $\lambda$ 很小，可能导致过拟合，高方差。
$C$ 较小时，相当于 $\lambda$ 很大，可能导致欠拟合，高偏差。

对于 SVM，若存在一个正样本，我们会希望代价函数中 $\theta^T x \ge 1$ 而不仅仅要求 $\theta^T x > 0$。这相当于在 SVM 中嵌入了一个额外的安全因子。
同样，对于一个负样本，我们会希望代价函数中 $\theta^T x \le 1$ 而不仅仅要求 $\theta^T x < 0$。这在 SVM 中表现为决策边界的间距。

支持向量机具有鲁棒性？因为其用一个最大间距来分离样本，因此有时支持向量机被称为大间距分类器。

### SVM 原理

支持向量机做的事情是 **极小化** 参数向量 $\theta$ 范数（长度）的平方。

支持向量机中参数向量 $\theta$ 是与决策边界 90 度 **正交** 的。
若决策边界选择不合理，那意味着样本在参数向量上的投影数值很小，若要求 $\theta^T x \ge 1$ 或者 $\theta^T x \le 1$ 则需要使得参数向量 $\theta$ 范数的平方很大，则会舍弃该决策边界。

### 核函数

用一系列新的特征 $f$ 来替代模型中的每一项，则
$$
h_\theta(x)=\theta_1 f_1 + \theta_2 f_2 + \cdots + \theta_n f_n
$$

#### 构造 $f$

给定一个训练实例 $x$，利用 $x$ 的各个特征与我们预先选定的地标（landmarks）$l^{(1)}，l^{(2)},l^{(3)}$ 的近似程度来选取新的特征 $f_1,f_2,f_3$。

一个核函数---**高斯核函数**
$$
f_1 = similarity(x, l^{(1)})= exp(-\frac{||x-l^{(1)}||^2}{2 \sigma^2})
$$
其中 $||x-l^{(1)}||^2=\sum_{j=1}^n(x_j-l_j^{(1)})^2$，为实例 $x$ 中所有特征与地标 $l^{(1)}$ 之间距离的和。

则，对于 $x$，如果其离地标 $l$ 距离近似为 0，则新特征 $f=1$；如果其离地标 $l$ 距离较远，则新特征 $f=0$。

随着 $x$ 的改变，$f$ 值改变的速率受到 $\sigma^2$ 的控制。
$\sigma^2$ 越大，改变速率越慢，可能导致高偏差。
$\sigma^2$ 越小，改变速率越快，可能导致高方差。

#### 如何选择地标

通常根据训练集的数量选择地标的数量，如果训练集中有 $m$ 个实例，则选择 $m$ 个地标，
并且令：$l^{(1)}=x^{(1)},l^{(2)}=x^{(3)},\cdots,l^{(m)}=x^{(m)}$。

好处：此时的新特征是建立在原有特征与训练集中所有其它特征之间距离的基础之上的。

### 修改支持向量机

给定 $x$，计算新特征 $f$，当 $\theta^Tf \ge 0$ 时，预测 $y=1$。否则反之。
相应的修改正则化项为：$\sum_{j=1}^{n=m}\theta_j^2=\theta^T\theta$。则有如下式子：
$$
\underset{\theta}{min}C\sum^m_{i = 1}[y^{(i)}cost_1(\theta^Tf^{(i)})+(1-y^{(i)})cost_0(\theta^Tf^{(i)})]+\frac12\theta^TM\theta
$$
其中 $M$ 是随核函数变化的一个矩阵。

### 使用支持向量机

$n$ 为特征数，$m$ 为训练样本数。

1. 若相较于 $m$ 而言，$n$ 大很多，即训练集数据量不够支持我们训练一个复杂的非线性模型，我们选用逻辑回归模型或者不带核函数的支持向量机。  
2. 若 $n$ 较小，而且 $m$ 大小中等，例如 $n$ 在 1-1000 之间，而 $m$ 在 10-10000 之间，选用高斯核函数的支持向量机。
3. 若 $n$ 较小，而且 $m$ 较大，例如 $n$ 在 1-1000 之间，而 $m$ 大于 50000，则使用支持向量机会非常慢，解决方案是创造、增加更多的特征，然后使用逻辑回归或不带核函数的支持向量机。  

选择支持向量机的原因在于它的代价函数为凸函数，不存在局部最小值。

## 聚类算法

这是一个非监督学习算法，其数据没有附带任何标签。

### K-均值算法

K-均值算法是最普及的聚类算法，其将未标记的数据聚类成不同组。

#### K-均值算法的思想

K-均值算法是一个迭代算法，假设将数据分为 K 组，其方法为：

1. 选择 K 个随机点，称为聚类中心
2. 对于数据集中的每一个数据，按照距离 K 个中心点的距离，将其与距离最近的中心点关起来，与同一个中心点关联的所有数据聚成一类。
3. 计算每一个类的平均值，将该类的中心点移到其平均值的位置。
4. 重复 2-3，直至中心点不再变化。





#### K-均值算法的优化目标

K-均值算法最小化问题，是要最小化所有的数据点与其所关联的聚类中心点之间的距离之和。因此 K-均值算法的代价函数（又称畸变函数 Distortion function）为：
$$
min \, J(c^{(1)}, c^{(2)},\cdots, c^{(n)},\mu^1,\mu^2,\cdots,\mu^k)=\frac 1m\sum_{i = 1}^m||X^{(i)}-\mu_{c^{(i)}}||^2
$$

#### K-均值算法的伪代码


$$
\begin{aligned}
& \text{Repeat} \{ \\
& \text{for i = 1 to m}  \\
& \text{c(i) := 距离实例数据最近的聚类中心的索引}  \\
& \text{for k = 1 to k}  \\
& \mu_k \text{ := 聚到该类的数据均值}  \\
& \} 
\end{aligned}
$$
其中第一个循环是用于减小 $c^{(i)}$ 引起的代价，第二个循环则是用于减小 $\mu_i$ 引起的代价。

#### 随机初始化

在运行 K-均值算法时，我们要随机初始化所有聚类中心点：

1. 应使得聚类中心点的个数 K 小于所有训练集实例的数量 m。
2. 随机选择 K 个训练实例，然后令 K 个聚类中心分别与 K 个训练实例相等。

K-均值算法可能会停留在局部最小值处，因此需要多次运行该算法，每一次都重新进行随机初始化，最后在选择使代价函数最小的结果。

#### 选择聚类数

利用 "肘部法则"，画出代价函数 J-聚类数目 K 的图像，当图像中出现一个拐点时，则可以选择该 K 值。



## 降维

特征之间可能存在高度冗余，可以采取降维将数据从高纬度降到低维度。

降维的原因：数据压缩、数据可视化。
数据压缩意义：减少数据占用的内存，加快学习算法。
数据可视化意义：将数据降低至低维，能够使得数据可视化，便于找到一个更好的解决方案。

### 主成分分析（PCA）

主成分分析（PCA）是最常见的降维算法。

在 PCA 中，我们需要找到一个方向向量，当把所有数据都投射到该向量上时，能够使得投射平均均方误差尽可能地小。
方向向量是一个经过原点的向量，而投射误差是从特征向量向该方向向量作垂线的长度。

当要将 n 维数据降至 k 维数据时，其目标是找到向量 $u^{(1)},u^{(2)},\cdots,u^{(k)}$ 使得总的投射误差最小。相比于线性回归，其不做任何预测。

PCA 的优点：其保证数据降维后特性损失最小；降维后结果只与数据相关，与用户是独立的。

### PCA 算法

PCA 减少 n 维到 k 维：

训练集 $x^{(1)},\cdots,x^{(m)}$

1. 均值归一化，计算所有特征的均值 $\mu_j=\frac1m\sum_{i=1}^m x_j^{(i)}$，然后令 $x_j=x_j - \,u_j$。如果特征是在不同的数量级上，我们还需要将其除以标准差 $\sigma^2$。
2. 计算协方差矩阵 $\Sigma= \frac1m \sum_{i=1}^m (x^{(i)})(x^{(i)})^T$
3. 对协方差矩阵 $\Sigma$ 进行求特征向量，得到特征矩阵（按特征值从大到小排列），提取千 K 列组成矩阵 $P_{n*k}$，$P$ 就相当于是一个坐标系，P 中的每一列就是一个坐标轴。
4. 将原始数据投影到 $P$ 坐标系下即可得到降维后的数据，$Y_{k*m}=P_{n*k}^T X_{n*m}$。其中降维后的向量 $z^{(i)}=P^T x^{(i)}$

### 选择主成分的数量

训练集的方差为：$\frac1m \sum_{i=1}^m||x^{(i)}||^2$

平均均方误差为：$\frac1m \sum_{i=1}^m||x^{(i)} - x_{approx}^{(i)}||^2$

选择的依据：在平均均方误差与训练集的比例尽可能小的情况下选择尽可能小的 k 值。

如果希望这个比例小于 1%，就意味着原本数据的偏差有 99%都保留下来了。

步骤：先确定保留的偏差，再从小到大选择 k，运行 PCA 算法，观察比例。

也可以采用特征矩阵（对角矩阵），则只需要修改上述方法为：
$$
\frac{\frac1m \sum_{i = 1}^m||x^{(i)} - x_{approx}^{(i)}||^2}{\frac1m \sum_{i = 1}^m||x^{(i)}||^2}= 1-\frac{\sum_{i = 1}^ks_{ii}}{\sum_{i = 1}^ms_{ii}}\le1 \%
$$

### PCA 重建

$x_{approx}^{(i)}=Pz^{(i)}$

### PCA 应用

当逻辑回归等算法，输入特征过大，可以先采用 PCA 将其输入特征压缩，再连带着原来的标注一起训练模型。利用验证集以及测试集验证该模型时，注意需要使用训练集得出的 PCA 特征矩阵的 $P$。



## 异常检测

虽然异常检测主要用于非监督学习问题，但从一些角度，其又类似于一些监督学习问题。

**异常检测定义**：给定数据集$x^{(1)},\cdots,x^{(m)}$，假设数据集是正常的，我们希望知道$x_{text}$是否正常，即这个测试数据不属于该组数据的几率如何 。我们所构建的模型应该能根据该测试数据的位置告诉我们其属于一组数据的可能性$p(x)$。

检测方法--密度估计
$$
if \quad p(x) \begin{cases}
< \epsilon \quad anomaly \\
\ge \epsilon \quad normal

\end{cases}
$$

###    高斯分布

若$x \sim N(\mu,\sigma^2)$，则其概率密度分布函数为$p(x,\mu,\sigma^2)=\frac{1}{\sqrt{2\pi} \sigma}exp(-\frac{(x-\mu)^2}{2 \sigma^2})$。

则 $\mu = \frac{1}{m}\sum^m_{i=1}x^{(i)}$，$\sigma^2=\frac1m\sum^m_{i=1}(x^{(i)}-\mu)^2$。
在机器学习中对于方差我们通常指除以$m$而非统计学中的$m-1$。

### 异常检测算法

应该高斯分布开发异常检测算法。

对于给定的数据集$x^{(1)},\cdots,x^{(m)}$，需要针对每一特征计算$\mu$和$\sigma^2$。则：
$$
\mu_j = \frac{1}{m}\sum^m_{i=1}x^{(i)}_j
$$

$$
\sigma^2_j=\frac1m\sum^m_{i=1}(x^{(i)}_j-\mu_j)^2
$$

则对于一个新的实例有
$$
p(x)=\prod_{j=1}^np(x_j;\mu_j;\sigma_j^2)=\prod_{j=1}^n\frac{1}{\sqrt{2\pi} \sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2 \sigma^2_j})
$$

### 评价一个异常检测系统

使用带标记（正常/异常）的数集着手，选择其中一部分正常数据用于构建训练集，然后用剩下的正常数据和异常数据混合的数据来构建验证集以及测试集。

具体评价方法如下：

1. 根据测试集数据，我们估计特征的平均值和方差并构建$p(x)$函数。
2. 对交叉检验集，我们尝试使用不同的$\epsilon$值作为阈值，并预测数据是否异常，根据F1值或者查准率与查全率的比例来选择$\epsilon $。
3. 选出$\epsilon$后，针对测试集进行预测，计算异常检验系统的F1值，或者查准率与查全率之比。

### 异常检测与监督学习对比

异常检测：

1.  有非常少量的正向类（异常数据 $y=1$），大量的负向类（$y=0$）。
2. 有许多不同种类的异常。根据非常少量的正向类数据来训练算法。
3. 未来遇到的异常可能与已掌握的异常、非常的不同。

监督学习：

1. 同时又大量的正向类和负向类
2. 有足够多的正向类实例，足够用于训练算法，未来遇到的正向类实例可能与训练集中的非常近似。

### 选择特征

异常检测假设特征符合高斯分布，如果数据的分布不是高斯分布，异常检测算法也能够工作，但是最好还是将数据转换成高斯分布。可以对特征进行一些小转换，如变为log，或者取一些指数等方法。

误差分析：有些异常的数据可能也会有较高的$p(x)$值，因而被算法认为是正常的。此时可通过误差分析，发现问题，并从中增加一些新的特征。将一些相关的特征进行组合。

## 推荐系统

假设有5部电影，4个用户。要求根据用户对电影的打分情况，为用户推荐电影，给指定用户未打分的电影ai打分。

引入一些标记：

$n_u$：用户的数量

$n_m$：电影的数量

$r(i,j)$：若用户$j$给电影$i$评过分，则$r(i,j)=1$.

$y^{(i,j)}$ ：用户$j$给电影$i$的评分

$m_j$：用户$j$评过分的电影的总数

### 基于内容的推荐系统

对于每部电影，假设有特征$x^{(i)}$。则基于这些特征来构建一个推荐系统算法。假设采用线性回归模型，且针对每一个用户都训练一个线性回归模型。有：

$\theta^{(j)}$为用户$j$的参数向量。

$x^{(i)}$ 为电影$i$的特征向量

对于用户$j$和电影$i$，我们的预测评分为$(\theta^{(j)})^Tx^{(i)}$

则对于用户$j$，其代价函数为：
$$
\min_{\theta^{(j)}} \frac{1}{2} \sum_{i: r(i,j)=1} \left( (\theta^{(j)})^T x^{(i)} - y^{(i,j)} \right)^2 + \frac{\lambda}{2} (\theta^{(j)}_k)^2
$$
其中$i: r(i,j)=1$表示只计算哪些用户$j$评价过的电影。

为了学习所有用户，我们将所有用户的代价函数求和：
$$
\min_{\theta^{(1)}, \ldots, \theta^{(n_u)}} \frac{1}{2} \sum_{j=1}^{n_u}\sum_{i: r(i,j)=1} \left( (\theta^{(j)})^T x^{(i)} - y^{(i,j)} \right)^2 + \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^{n} \left( \theta_k^{(j)} \right)^2
$$
用梯度下降算法求最优解，则：
$$
\theta_k^{(j)}:=\theta_k^{(j)} - \alpha\sum_{i:r(i,j)=1}((\theta^{j})^Tx^{(i)}-y^{(i,j)})x_k^{(i)} \quad(for \, k = 0)
$$

$$
\theta_k^{(j)}:=\theta_k^{(j)} - \alpha(\sum_{i:r(i,j)=1}((\theta^{j})^Tx^{(i)}-y^{(i,j)})x_k^{(i)} + \lambda \theta_k^{(j)}) \quad(for \, k \ne 0)
$$

### 协同过滤

前面，基于每一部电影可用的特征，我们可训练得到每一个用户的参数。同样，如果我们有用户的参数，我们则可以学习出电影的特征。
$$
\min_{x^{(1)},\cdots,x^{(n_m)}} \frac{1}{2} \sum_{i=1}^{n_m} \sum_{j: r(i,j)=1} \left( \left( \theta^{(j)} \right)^T x^{(i)} - y^{(i,j)} \right)^2 + \frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n \left( x_k^{(i)} \right)^2
$$
假如既没有用户的参数，也没有电影的特征。则不能采用上述的两种方法。则可采用协同过滤来同时学习这两者，其代价函数为：
$$
J(x^{(1)},\ldots,x^{(n_m)},\theta^{(1)},\ldots,\theta^{(n_u)}) \\= \frac{1}{2} \sum_{(i:j):r(i,j)=1} \left( \left( \theta^{(j)} \right)^T x^{(i)} - y^{(i,j)} \right)^2 + \frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n \left( x_k^{(i)} \right)^2 \\
\quad + \frac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n \left( \theta_k^{(j)} \right)^2
$$
采用梯度下降法寻找最小值：
$$
x_k^{(i)} := x_k^{(i)} - \alpha \left( \sum_{j: r(i,j)=1} \left( \left( \theta^{(j)} \right)^T x^{(i)} - y^{(i,j)} \right) \theta_k^{(j)} + \lambda x_k^{(i)} \right) \\
\theta_k^{(j)} := \theta_k^{(j)} - \alpha \left( \sum_{i: r(i,j)=1} \left( \left( \theta^{(j)} \right)^T x^{(i)} - y^{(i,j)} \right) x_k^{(i)} + \lambda \theta_k^{(j)} \right) \\
\min_{x^{(1)},\ldots,x^{(n_m)}} \frac{1}{2} \sum_{i=1}^{n_m} \sum_{j: r(i,j)=1} \left( \left( \theta^{(j)} \right)^T x^{(i)} - y^{(i,j)} \right)^2 + \frac{\lambda}{2} \sum_{i=1}^{n_m} \sum_{k=1}^n \left( x_k^{(i)} \right)^2
$$
协同过滤算法使用步骤如下：

1. 初始$x^{(1)}, x^{(2)}, \ldots, x^{(nm)}, \theta^{(1)}, \theta^{(2)}, \ldots, \theta^{(n_u)}$为一些随机最小值。
2. 使用梯度下降法来最小化代价函数
3. 训练完算法后，我们预测$(\theta^{(j)})^Tx^{(i)}$为用户$j$给电影$i$评分

### 均值归一化

若新增一个用户，其没有为任何电影评过分。可用均值归一化的方法为其推荐电影。

步骤：

1. 对结果Y矩阵进行均值归一化处理，将每一个用户对某一电影的评分减去所有用户对该电影评分的平均值。
2. 然后利用新的Y矩阵来训练算法。
3. 训练完毕后需要将平均值加回去。
4. 对于新用户，该算法认为他给每部电影的评分都是该电影的平均值。



## 大规模机器学习

对于大型数据集的学习，首先要做的事是，去检查一个大规模的训练集是否真的有必要。可以绘制学习曲线来帮助判断。

若一定需要一个大规模的训练集，可以采用**随机梯度下降法（SGD）**来代替批量梯度下降法。

### 随机梯度下降法

在随机梯度下降法中，我们定义代价函数为一个单一训练实例的代价：
$$
cost(\theta,(x^{(i)},y{(i)}))=\frac12(h_\theta(x^{(i)})-y^{(i)})^2
$$
随机梯度下降算法为：
首先对训练集进行随机洗牌，然后：
$$
\begin{aligned}
& Repeat \{ \\
& \quad for \, i=1:m \{ \\
& \quad  \theta_j:=\theta_j - \alpha(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)} \\
& \quad  (for \, j=0:n) \\
& \quad  \} \\
& \}
\end{aligned}
$$
随机梯度下降算法在每一次计算之后便更新参数$\theta$，不需要首先将所有的训练集求和，在梯度下降算法还没有完成一次迭代时，随机梯度下降算法便已经走出了很远。但是这样的算法存在的问题是，不是每一步都是朝着”正确”的方向迈出的。因此算法虽然会逐渐走向全局最小值的位置，但是可能无法站到那个最小值的那一点，而是在最小值点附近徘徊。  

### 小批量梯度下降算法

小批量梯度下降算法是介于批量梯度下降算法和随机梯度下降算法之间的算法，每计算
常数b次训练实例，便会更新一次参数$\theta$。
$$
\begin{aligned}
& Repeat \{ \\
& \quad for \, i=1:m \{ \\
& \quad  \theta_j:=\theta_j - \alpha\frac{1}{b}\sum_{k=i}^{i+b-1}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)} \\
& \quad  (for \, j=0:n) \\
& \quad i+=b \\
& \quad  \} \\
& \}
\end{aligned}
$$
通常会令b在2-100之间。

### 随机梯度下降收敛

如何对随机梯度下降算法进行调试以及选取学习率$\alpha$？

在随机梯度下降中，我们在每一次更新$\theta$前都计算一次代价，然后每x次迭代后，求出这x次对训练实例计算代价的平均值，然后绘制这些平均值宇x次迭代的次数之间的函数图表。

1. 若曲线发散，则选取较小学习率。
2. 曲线在收敛，但噪声比较大（曲线小幅度上下起伏），选取较小学习率，或增大x。
3. 曲线基本保持平坦，模型有错误，或者增大x。

### 在线学习

在线学习算法指的是对数据流而非离线的静态数据集的学习。

若有一个由连续的用户流引发的连续的数据流，则可以使用在线学习机制，从数据流中学习用户的偏好，然后使用这些信息来优化一些关于网站的决策。

其与随机梯度下降算法有些类似，都对单一的实例进行学习。
$$
\begin{aligned}
& Repeat \,forever(\text{若网站一直在运行}) \{ \\
& \quad \text{获取数据}(x,y)  \\
& \quad  \theta_j:=\theta_j - \alpha(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)} \\
& \quad  (for \, j=0:n) \\
& \}
\end{aligned}
$$

### 映射简化

映射简化：将数据集分配给不同台计算机，让每一台计算机处理数据集的一个子集，然后将计算结果汇总求和。（或是一台计算机的多个核）



## 其它

### 大量数据获取

利用已有的数据，对其进行修改，如将已又的字符图片进行一些扭曲、旋转、模糊处理。只要认为实际数据又可能核经过这样处理后的数据类似，我们就可以采用这样的方法来创造大量数据。

有关获取数据的几种方法：

1. 人工数据合成
2. 手动收集、标注数据
3. 众包

### 上限分析

在机器学习应用中，我们通常需要通过几个步骤才能进行最终的预测，**利用上限分析可以知道哪一个步骤最值得投入时间**。

每一个步骤中，上一个步骤的输出是下一个步骤的输入。在上限分析中，我们选取一个步骤，手工提供100%正确的输出结果，然后看应用的整体效果提升了多少。若提升效果较大，则可投入大量精力至该步骤中；反之，该步骤对模型整体性能提升效果不大。





































